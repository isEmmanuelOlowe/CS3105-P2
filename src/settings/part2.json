{
    "n_hidden_layers": 1,
    "n_nodes_per_hidden_layer": 10,
    "activation_function": "ReLU",
    "learning_rate": 0.01,
    "batchsize": 64,
    "nEpochs": 2000,
    "patience": 200
}
