{
    "n_hidden_layers": 1,
    "n_nodes_per_hidden_layer": 32,
    "activation_function": "ReLU",
    "learning_rate": 1.1032,
    "batchsize": 128,
    "nEpochs": 2000,
    "patience": 100
}
