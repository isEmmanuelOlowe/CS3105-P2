{
    "n_hidden_layers": 4,
    "n_nodes_per_hidden_layer": 15,
    "activation_function": "ReLU",
    "learning_rate": 0.3,
    "batchsize": 64,
    "nEpochs": 2000,
    "patience": 1000
}
